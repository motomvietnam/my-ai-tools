import streamlit as st
import google.generativeai as genai
import requests # Th∆∞ vi·ªán ƒë·ªÉ g·ªçi API t·∫°o ·∫£nh
import json # ƒê·ªÉ x·ª≠ l√Ω JSON

st.set_page_config(page_title="AUTO CONTENT AI", layout="centered")
st.title("üöÄ AUTO VI·∫æT CONTENT ƒêƒÇNG B√ÄI")

# 1. C·∫•u h√¨nh API t·ª´ Secrets
if "GEMINI_KEY" not in st.secrets:
    st.error("L·ªói: B·∫°n ch∆∞a d√°n API Key Gemini v√†o m·ª•c Secrets c·ªßa Streamlit!")
    st.stop()

genai.configure(api_key=st.secrets["GEMINI_KEY"])

# 2. Kh·ªüi t·∫°o API Key DALL-E (Cho t√≠nh nƒÉng t·∫°o h√¨nh ·∫£nh)
# B·∫°n C·∫¶N T·∫†O m·ªôt SECRET m·ªõi t√™n l√† DALL_E_KEY = "sk-..."
OPENAI_API_KEY = st.secrets.get("DALL_E_KEY") 
if not OPENAI_API_KEY:
    st.warning("‚ö†Ô∏è ƒê·ªÉ T·∫†O H√åNH ·∫¢NH, vui l√≤ng th√™m DALL_E_KEY (OpenAI API Key) v√†o Streamlit Secrets.")

# 3. H√†m t·ª± ƒë·ªông t√¨m Model kh·∫£ d·ª•ng (Gi·ªØ nguy√™n t·ª´ code g·ªëc c·ªßa b·∫°n)
@st.cache_resource
def find_working_model():
    test_names = ['gemini-1.5-flash', 'gemini-1.5-pro', 'gemini-pro']
    try:
        available_models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
        if available_models:
            for name in test_names:
                full_name = f"models/{name}"
                if full_name in available_models or name in available_models:
                    return genai.GenerativeModel(name)
            return genai.GenerativeModel(available_models[0])
    except:
        return genai.GenerativeModel('gemini-pro')
    return None

model = find_working_model()

# --- H√†m T·∫°o H√¨nh ·∫£nh b·∫±ng DALL-E 3 ---
def generate_image_with_dalle(prompt_text):
    if not OPENAI_API_KEY:
        st.error("Kh√¥ng t√¨m th·∫•y DALL_E_KEY. Vui l√≤ng th√™m v√†o Streamlit Secrets ƒë·ªÉ t·∫°o ·∫£nh.")
        return None

    headers = {
        "Authorization": f"Bearer {OPENAI_API_KEY}",
        "Content-Type": "application/json"
    }
    data = {
        "model": "dall-e-3",
        "prompt": prompt_text,
        "n": 1,
        "size": "1024x1024" 
    }
    
    try:
        response = requests.post("https://api.openai.com/v1/images/generations", headers=headers, json=data)
        response.raise_for_status() # B√°o l·ªói n·∫øu status code kh√¥ng ph·∫£i 200
        image_url = response.json()["data"][0]["url"]
        return image_url
    except requests.exceptions.RequestException as e:
        st.error(f"L·ªói khi g·ªçi API DALL-E: {e}")
        try:
            st.json(response.json()) # In ra chi ti·∫øt l·ªói t·ª´ API n·∫øu c√≥
        except:
            pass
        return None

# 4. Giao di·ªán ng∆∞·ªùi d√πng
if model:
    topic = st.text_area("S·∫£n ph·∫©m c·ªßa b·∫°n l√† g√¨?", placeholder="V√≠ d·ª•: M·ªπ ph·∫©m tr·ªã m·ª•n, Kh√≥a h·ªçc ƒë·∫ßu t∆∞...")
    
    if st.button("T·∫°o b√†i vi·∫øt & H√¨nh ·∫£nh & Ki·ªÉm tra Policy"):
        if topic:
            try:
                # --- B∆Ø·ªöC 1: T·∫†O N·ªòI DUNG ---
                with st.spinner('H·ªá th·ªëng ƒëang vi·∫øt b√†i qu·∫£ng c√°o...'):
                    prompt_content = f"Vi·∫øt b√†i qu·∫£ng c√°o Facebook h·∫•p d·∫´n, s·ª≠ d·ª•ng emoji, t·ªëi ∆∞u chuy·ªÉn ƒë·ªïi v·ªÅ: {topic}"
                    response_content = model.generate_content(prompt_content)
                    bai_viet = response_content.text
                    
                    st.success("‚úÖ ƒê√É T·∫†O B√ÄI VI·∫æT")
                    st.markdown(bai_viet)
                    st.markdown("---")

               def generate_image_with_dalle(prompt_text):
    if not OPENAI_API_KEY:
        return None
    headers = {
        "Authorization": f"Bearer {OPENAI_API_KEY}",
        "Content-Type": "application/json"
    }
    data = {"model": "dall-e-3", "prompt": prompt_text, "n": 1, "size": "1024x1024"}
    
    try:
        response = requests.post("https://api.openai.com/v1/images/generations", headers=headers, json=data, timeout=30)
        if response.status_code == 200:
            return response.json()["data"][0]["url"]
        else:
            # N·∫øu h·∫øt ti·ªÅn ho·∫∑c l·ªói, tr·∫£ v·ªÅ None ch·ª© kh√¥ng b√°o l·ªói ƒë·ªè 
            return None
    except:
        return None


                # --- B∆Ø·ªöC 3: KI·ªÇM TRA VI PH·∫†M (POLICY) ---
                st.subheader("üõ°Ô∏è KI·ªÇM TRA VI PH·∫†M CH√çNH S√ÅCH FB")
                with st.spinner('AI ƒëang ph√¢n t√≠ch vi ph·∫°m...'):
                    prompt_policy = f"Ph√¢n t√≠ch b√†i vi·∫øt sau xem c√≥ vi ph·∫°m ch√≠nh s√°ch qu·∫£ng c√°o Facebook kh√¥ng (c√°c t·ª´ kh√≥a b·ªã c·∫•m, cam k·∫øt qu√° m·ª©c, t·ª´ nh·∫°y c·∫£m v·ªÅ c∆° th·ªÉ, y t·∫ø...): {bai_viet}"
                    policy_response = model.generate_content(prompt_policy)
                    st.info(policy_feedback := policy_response.text)

            except Exception as e:
                st.error(f"L·ªói khi x·ª≠ l√Ω: {e}")
        else:
            st.warning("Vui l√≤ng nh·∫≠p th√¥ng tin s·∫£n ph·∫©m!")
else:
    st.error("Kh√¥ng th·ªÉ k·∫øt n·ªëi v·ªõi b·∫•t k·ª≥ Model AI n√†o. H√£y ki·ªÉm tra l·∫°i API Key Gemini.")

