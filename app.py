import streamlit as st
import google.generativeai as genai
import requests # Th∆∞ vi·ªán ƒë·ªÉ g·ªçi API t·∫°o ·∫£nh
import json # ƒê·ªÉ x·ª≠ l√Ω JSON

st.set_page_config(page_title="AUTO CONTENT AI", layout="centered")
st.title("üöÄ AUTO VI·∫æT CONTENT ƒêƒÇNG B√ÄI")

# 1. C·∫•u h√¨nh API t·ª´ Secrets
if "GEMINI_KEY" not in st.secrets:
    st.error("L·ªói: B·∫°n ch∆∞a d√°n API Key Gemini v√†o m·ª•c Secrets c·ªßa Streamlit!")
    st.stop()

genai.configure(api_key=st.secrets["GEMINI_KEY"])

# 2. Kh·ªüi t·∫°o API Key DALL-E (Cho t√≠nh nƒÉng t·∫°o h√¨nh ·∫£nh)
# B·∫°n C·∫¶N T·∫†O m·ªôt SECRET m·ªõi t√™n l√† DALL_E_KEY = "sk-..."
OPENAI_API_KEY = st.secrets.get("DALL_E_KEY") 
if not OPENAI_API_KEY:
    st.warning("‚ö†Ô∏è ƒê·ªÉ T·∫†O H√åNH ·∫¢NH, vui l√≤ng th√™m DALL_E_KEY (OpenAI API Key) v√†o Streamlit Secrets.")

# 3. H√†m t·ª± ƒë·ªông t√¨m Model kh·∫£ d·ª•ng (Gi·ªØ nguy√™n t·ª´ code g·ªëc c·ªßa b·∫°n)
@st.cache_resource
def find_working_model():
    test_names = ['gemini-1.5-flash', 'gemini-1.5-pro', 'gemini-pro']
    try:
        available_models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
        if available_models:
            for name in test_names:
                full_name = f"models/{name}"
                if full_name in available_models or name in available_models:
                    return genai.GenerativeModel(name)
            return genai.GenerativeModel(available_models[0])
    except:
        return genai.GenerativeModel('gemini-pro')
    return None

model = find_working_model()

# --- H√†m T·∫°o H√¨nh ·∫£nh b·∫±ng DALL-E 3 ---
def generate_image_with_dalle(prompt_text):
    if not OPENAI_API_KEY:
        st.error("Kh√¥ng t√¨m th·∫•y DALL_E_KEY. Vui l√≤ng th√™m v√†o Streamlit Secrets ƒë·ªÉ t·∫°o ·∫£nh.")
        return None

    headers = {
        "Authorization": f"Bearer {OPENAI_API_KEY}",
        "Content-Type": "application/json"
    }
    data = {
        "model": "dall-e-3",
        "prompt": prompt_text,
        "n": 1,
        "size": "1024x1024" 
    }
    
    try:
        response = requests.post("https://api.openai.com/v1/images/generations", headers=headers, json=data)
        response.raise_for_status() # B√°o l·ªói n·∫øu status code kh√¥ng ph·∫£i 200
        image_url = response.json()["data"][0]["url"]
        return image_url
    except requests.exceptions.RequestException as e:
        st.error(f"L·ªói khi g·ªçi API DALL-E: {e}")
        try:
            st.json(response.json()) # In ra chi ti·∫øt l·ªói t·ª´ API n·∫øu c√≥
        except:
            pass
        return None

# 4. Giao di·ªán ng∆∞·ªùi d√πng
if model:
    topic = st.text_area("S·∫£n ph·∫©m c·ªßa b·∫°n l√† g√¨?", placeholder="V√≠ d·ª•: M·ªπ ph·∫©m tr·ªã m·ª•n, Kh√≥a h·ªçc ƒë·∫ßu t∆∞...")
    
    if st.button("T·∫°o b√†i vi·∫øt & H√¨nh ·∫£nh & Ki·ªÉm tra Policy"):
        if topic:
            try:
                # --- B∆Ø·ªöC 1: T·∫†O N·ªòI DUNG ---
                with st.spinner('H·ªá th·ªëng ƒëang vi·∫øt b√†i qu·∫£ng c√°o...'):
                    prompt_content = f"Vi·∫øt b√†i qu·∫£ng c√°o Facebook h·∫•p d·∫´n, s·ª≠ d·ª•ng emoji, t·ªëi ∆∞u chuy·ªÉn ƒë·ªïi v·ªÅ: {topic}"
                    response_content = model.generate_content(prompt_content)
                    bai_viet = response_content.text
                    
                    st.success("‚úÖ ƒê√É T·∫†O B√ÄI VI·∫æT")
                    st.markdown(bai_viet)
                    st.markdown("---")

                # --- B∆Ø·ªöC 2: T·∫†O H√åNH ·∫¢NH ---
                st.subheader("üñºÔ∏è H√åNH ·∫¢NH ƒêƒÇNG B√ÄI (AI T·∫°o)")
                if OPENAI_API_KEY:
                    with st.spinner('AI ƒëang t·∫°o h√¨nh ·∫£nh...'):
                        # AI s·∫Ω t·∫°o prompt ·∫£nh t·ª´ ch√≠nh b√†i vi·∫øt ho·∫∑c t·ª´ topic
                        image_prompt_text = f"M·ªôt h√¨nh ·∫£nh qu·∫£ng c√°o ƒë·ªôc ƒë√°o, ch·∫•t l∆∞·ª£ng cao cho s·∫£n ph·∫©m/d·ªãch v·ª•: {topic}. Phong c√°ch hi·ªán ƒë·∫°i, thu h√∫t. T·∫≠p trung v√†o l·ª£i √≠ch kh√°ch h√†ng."
                        image_url = generate_image_with_dalle(image_prompt_text)
                        if image_url:
                            st.image(image_url, caption="H√¨nh ·∫£nh ƒë∆∞·ª£c t·∫°o b·ªüi AI (DALL-E 3)", use_column_width=True)
                        else:
                            st.warning("Kh√¥ng th·ªÉ t·∫°o h√¨nh ·∫£nh. Vui l√≤ng ki·ªÉm tra DALL_E_KEY ho·∫∑c th·ª≠ l·∫°i.")
                else:
                    st.info("T√≠nh nƒÉng t·∫°o h√¨nh ·∫£nh y√™u c·∫ßu DALL_E_KEY trong Streamlit Secrets.")
                st.markdown("---")


                # --- B∆Ø·ªöC 3: KI·ªÇM TRA VI PH·∫†M (POLICY) ---
                st.subheader("üõ°Ô∏è KI·ªÇM TRA VI PH·∫†M CH√çNH S√ÅCH FB")
                with st.spinner('AI ƒëang ph√¢n t√≠ch vi ph·∫°m...'):
                    prompt_policy = f"Ph√¢n t√≠ch b√†i vi·∫øt sau xem c√≥ vi ph·∫°m ch√≠nh s√°ch qu·∫£ng c√°o Facebook kh√¥ng (c√°c t·ª´ kh√≥a b·ªã c·∫•m, cam k·∫øt qu√° m·ª©c, t·ª´ nh·∫°y c·∫£m v·ªÅ c∆° th·ªÉ, y t·∫ø...): {bai_viet}"
                    policy_response = model.generate_content(prompt_policy)
                    st.info(policy_feedback := policy_response.text)

            except Exception as e:
                st.error(f"L·ªói khi x·ª≠ l√Ω: {e}")
        else:
            st.warning("Vui l√≤ng nh·∫≠p th√¥ng tin s·∫£n ph·∫©m!")
else:
    st.error("Kh√¥ng th·ªÉ k·∫øt n·ªëi v·ªõi b·∫•t k·ª≥ Model AI n√†o. H√£y ki·ªÉm tra l·∫°i API Key Gemini.")
